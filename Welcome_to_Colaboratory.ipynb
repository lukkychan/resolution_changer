{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukkychan/resolution_changer/blob/main/Welcome_to_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pytube"
      ],
      "metadata": {
        "id": "3njVD55u8WTP",
        "outputId": "85e3153d-17f7-478f-d345-2a8acb6002b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install moviepy imageio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM_CZ8MVFGO8",
        "outputId": "94ab8976-6115-4a8c-a5d5-cb0d969325f8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.25.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.27.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.22.4)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/Data/Videos_nosound\""
      ],
      "metadata": {
        "id": "nt9ozPkrcvQ0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytube\n",
        "\n",
        "\n",
        "# Specify the YouTube video URL\n",
        "video_url = \"https://www.youtube.com/watch?v=O5LW6HABcRA&pp=ygUQcmFkaGVzaHlhbSBzb25ncw%3D%3D\"\n",
        "\n",
        "# Create a YouTube object to access video details\n",
        "youtube = pytube.YouTube(video_url)\n",
        "\n",
        "# Get the available video streams\n",
        "video_streams = youtube.streams.filter(file_extension='mp4').all()\n",
        "\n",
        "# Print the available video streams and their resolutions\n",
        "for i, stream in enumerate(video_streams):\n",
        "    print(f\"{i+1}. Resolution: {stream.resolution}, Format: {stream.mime_type}\")\n",
        "\n",
        "# Specify the desired resolution (e.g., \"720p\")\n",
        "desired_resolution = \"1080p\"\n",
        "\n",
        "# Find the stream with the desired resolution\n",
        "selected_stream = None\n",
        "for stream in video_streams:\n",
        "    if stream.resolution == desired_resolution:\n",
        "        selected_stream = stream\n",
        "        break\n",
        "\n",
        "# Download the video with the selected stream\n",
        "if selected_stream is not None:\n",
        "    print(f\"\\nDownloading video with {selected_stream.resolution} resolution...\")\n",
        "    selected_stream.download(output_path=\"/content/Data/Videos/\")\n",
        "    print(\"Video downloaded successfully!\")\n",
        "else:\n",
        "    print(\"Desired resolution not found. Please select another resolution.\")\n"
      ],
      "metadata": {
        "id": "SKgP9hvy7klH",
        "outputId": "fdc92427-f381-4661-cc67-16f7952c08ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-ca3728c65db1>:10: DeprecationWarning: Call to deprecated function all (This object can be treated as a list, all() is useless).\n",
            "  video_streams = youtube.streams.filter(file_extension='mp4').all()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Resolution: 360p, Format: video/mp4\n",
            "2. Resolution: 720p, Format: video/mp4\n",
            "3. Resolution: 1080p, Format: video/mp4\n",
            "4. Resolution: 720p, Format: video/mp4\n",
            "5. Resolution: 480p, Format: video/mp4\n",
            "6. Resolution: 360p, Format: video/mp4\n",
            "7. Resolution: 240p, Format: video/mp4\n",
            "8. Resolution: 144p, Format: video/mp4\n",
            "9. Resolution: None, Format: audio/mp4\n",
            "10. Resolution: None, Format: audio/mp4\n",
            "\n",
            "Downloading video with 1080p resolution...\n",
            "Video downloaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Specify the path to the video file\n",
        "video_path = \"/content/Data/Videos/1080p.mp4\"\n",
        "\n",
        "# Specify the output folder to save the frames\n",
        "output_folder = \"/content/Data/frames/1080p/\"\n",
        "\n",
        "# Specify the maximum number of frames to extract\n",
        "max_frames = 50\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Calculate the frame interval to evenly sample the frames\n",
        "frame_interval = max(total_frames // max_frames, 1)\n",
        "\n",
        "# Initialize a counter to keep track of the extracted frames\n",
        "frame_count = 0\n",
        "\n",
        "# Loop through the frames and extract the desired number of frames\n",
        "while frame_count < max_frames:\n",
        "    # Read the current frame\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Check if the frame was successfully read\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Save the frame as an image file\n",
        "    frame_path = f\"{output_folder}frame_{frame_count}.jpg\"\n",
        "    cv2.imwrite(frame_path, frame)\n",
        "\n",
        "    # Increment the frame count\n",
        "    frame_count += 1\n",
        "\n",
        "    # Move to the next frame based on the frame interval\n",
        "    video.set(cv2.CAP_PROP_POS_FRAMES, frame_count * frame_interval)\n",
        "\n",
        "# Release the video capture object\n",
        "video.release()\n"
      ],
      "metadata": {
        "id": "-1C8AxZyaidw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Specify the path to the input video file\n",
        "input_video_path = \"/content/Data/Videos/1080p.mp4\"\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "# Get the total number of frames in the video\n",
        "total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# Print the total number of frames\n",
        "print(f\"Total frames in the video: {total_frames}\")\n",
        "\n",
        "# Release the video file\n",
        "video.release()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_V6jvPhKRqn",
        "outputId": "aae6dceb-1900-47ed-c52f-eaa5931a46e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total frames in the video: 5909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reomove audio and make frames\n",
        "from moviepy.editor import VideoFileClip\n",
        "import imageio\n",
        "# Specify the path to the input video file\n",
        "input_video_path = \"/content/Data/Videos/1080p.mp4\"\n",
        "\n",
        "# Specify the path to save the output video without audio\n",
        "output_video_path = \"/content/Data/Videos_nosound/1080p.mp4\"\n",
        "\n",
        "# Specify the path to save the extracted frames\n",
        "output_frames_path = \"/content/Data/frames/1080/\"\n",
        "\n",
        "# Load the video clip\n",
        "video_clip = VideoFileClip(input_video_path)\n",
        "\n",
        "# Remove the audio from the video\n",
        "#video_clip_without_audio = video_clip.without_audio()\n",
        "\n",
        "# Save the video without audio\n",
        "#video_clip_without_audio.write_videofile(output_video_path)\n",
        "\n",
        "# Extract frames from the video\n",
        "#frames = video_clip_without_audio.iter_frames()\n",
        "frames = video_clip.iter_frames()\n",
        "\n",
        "# Save each frame as an image\n",
        "for i, frame in enumerate(frames):\n",
        "    frame_path = output_frames_path + f\"frame_{i}.jpg\"\n",
        "    imageio.imwrite(frame_path, frame)\n",
        "    print(f\"Frame {i} saved as {frame_path}\")\n"
      ],
      "metadata": {
        "id": "7QZSpWA6FM7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Specify the folder path\n",
        "folder_path = \"/path/to/folder\"\n",
        "\n",
        "# Specify the file name to check\n",
        "file_name = \"example.txt\"\n",
        "\n",
        "# Get a list of all files in the folder\n",
        "files = os.listdir(folder_path)\n",
        "\n",
        "# Check if the file exists in the folder\n",
        "if file_name in files:\n",
        "    print(f\"The file '{file_name}' exists in the folder.\")\n",
        "else:\n",
        "    print(f\"The file '{file_name}' does not exist in the folder.\")\n"
      ],
      "metadata": {
        "id": "BmCeqDpxV-V4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import os"
      ],
      "metadata": {
        "id": "rOgk2de55x_A"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the super-resolution model architecture\n",
        "def create_super_resolution_model():\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Add convolutional layers for feature extraction\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, activation='relu', padding='same', input_shape=(None, None, 3)))\n",
        "    model.add(layers.Conv2D(64, kernel_size=3, activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2D(32, kernel_size=3, activation='relu', padding='same'))\n",
        "\n",
        "    # Add upsampling layers for increasing resolution\n",
        "    model.add(layers.Conv2DTranspose(32, kernel_size=3, activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2DTranspose(64, kernel_size=3, activation='relu', padding='same'))\n",
        "    model.add(layers.Conv2DTranspose(3, kernel_size=3, activation='relu', padding='same'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create an instance of the super-resolution model\n",
        "model = create_super_resolution_model()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Load and preprocess your high-resolution and low-resolution image data\n",
        "# X_train: low-resolution images, y_train: corresponding high-resolution images\n",
        "# Make sure your data is properly preprocessed and normalized\n",
        "\n",
        "# Define the paths to your high-resolution and low-resolution image datasets\n",
        "high_res_dir = \"/content/Data/frames/1080p/\"\n",
        "low_res_dir = \"/content/Data/frames/144p/\"\n",
        "\n",
        "# Define the dimensions of your low-resolution images\n",
        "low_res_width, low_res_height = 256, 144\n",
        "\n",
        "# Load and preprocess the image data\n",
        "import os\n",
        "\n",
        "def load_and_preprocess_images(high_res_dir, low_res_dir, low_res_width, low_res_height):\n",
        "    high_res_images = []\n",
        "    low_res_images = []\n",
        "\n",
        "    high_res_files = os.listdir(high_res_dir)\n",
        "    low_res_files = os.listdir(low_res_dir)\n",
        "\n",
        "    # Load high-resolution and low-resolution images\n",
        "    for high_res_file, low_res_file in zip(high_res_files, low_res_files):\n",
        "        high_res_path = os.path.join(high_res_dir, high_res_file)\n",
        "        low_res_path = os.path.join(low_res_dir, low_res_file)\n",
        "\n",
        "        high_res_image = Image.open(high_res_path)\n",
        "        low_res_image = Image.open(low_res_path)\n",
        "\n",
        "        # Resize the high-resolution image\n",
        "        high_res_image = high_res_image.resize((low_res_width, low_res_height))\n",
        "\n",
        "        # Resize the low-resolution image\n",
        "        #low_res_image = low_res_image.resize((low_res_width, low_res_height))\n",
        "\n",
        "        # Convert images to arrays\n",
        "        high_res_image = img_to_array(high_res_image)\n",
        "        low_res_image = img_to_array(low_res_image)\n",
        "\n",
        "        high_res_images.append(high_res_image)\n",
        "        low_res_images.append(low_res_image)\n",
        "\n",
        "    # Convert the lists to numpy arrays\n",
        "    high_res_images = np.array(high_res_images)\n",
        "    low_res_images = np.array(low_res_images)\n",
        "\n",
        "    # Normalize the image data to values between 0 and 1\n",
        "    high_res_images = high_res_images / 255.0\n",
        "    low_res_images = low_res_images / 255.0\n",
        "\n",
        "    return high_res_images, low_res_images\n",
        "\n",
        "\n",
        "\n",
        "# Call the function to load and preprocess the image data\n",
        "X_train, y_train = load_and_preprocess_images(high_res_dir, low_res_dir, low_res_width, low_res_height)\n",
        "\n",
        "# Train the model using the high-resolution and low-resolution images\n",
        "model.fit(X_train, y_train, batch_size=16, epochs=10, validation_split=0.2)\n",
        "\n",
        "# Specify the path to save the trained model\n",
        "save_path = \"/content/Data/model.h5\"\n",
        "\n",
        "# Save the trained model\n",
        "model.save(save_path)\n"
      ],
      "metadata": {
        "id": "BB4d-EabY63H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model = tf.keras.models.load_model(\"/content/Data/model.h5\")\n",
        "\n",
        "# Path to the low-resolution input image\n",
        "input_image_path = \"/content/Data/frames/144p/frame_10.jpg\"\n",
        "\n",
        "# Desired dimensions of the low-resolution image\n",
        "low_res_width, low_res_height = 64,64\n",
        "\n",
        "# Load and resize the low-resolution input image\n",
        "input_image = Image.open(input_image_path)\n",
        "print(input_image)\n",
        "input_image = input_image.resize((low_res_width, low_res_height))\n",
        "\n",
        "# Convert the input image to a numpy array\n",
        "input_image = tf.keras.preprocessing.image.img_to_array(input_image)\n",
        "\n",
        "# Preprocess the input image by normalizing it to values between 0 and 1\n",
        "input_image = input_image / 255.0\n",
        "print(input_image)\n",
        "\n",
        "# Reshape the input image to match the model's input shape\n",
        "input_image = tf.expand_dims(input_image, axis=0)\n",
        "\n",
        "# Feed the preprocessed low-resolution image into the trained model\n",
        "predicted_image = model.predict(input_image)\n",
        "\n",
        "# Rescale the predicted image back to the original high-resolution dimensions\n",
        "predicted_image = tf.image.resize(predicted_image, (1080, 1920))\n",
        "\n",
        "# Convert the predicted image to a numpy array\n",
        "predicted_image = tf.squeeze(predicted_image, axis=0).numpy()\n",
        "print(predicted_image.astype(\"uint8\"))\n",
        "# Post-process the predicted image if necessary\n",
        "# ...\n",
        "\n",
        "# Display or save the predicted high-resolution image\n",
        "predicted_image = Image.fromarray(predicted_image.astype(\"uint8\"))\n",
        "\n",
        "#predicted_image.show()\n",
        "predicted_image.save(\"/content/Data/image.jpg\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZQShKLKgNvC",
        "outputId": "048e8d6d-4af0-4b05-a9fa-43c03fdf01c4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x144 at 0x7FE08F2D2050>\n",
            "[[[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]\n",
            "\n",
            " [[0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  ...\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]\n",
            "  [0. 0. 0.]]]\n",
            "1/1 [==============================] - 0s 107ms/step\n",
            "[[[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  ...\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  ...\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  ...\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  ...\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  ...\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]\n",
            "\n",
            " [[0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  ...\n",
            "  [0 0 0]\n",
            "  [0 0 0]\n",
            "  [0 0 0]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model(\"path_to_your_trained_model.h5\")\n",
        "\n",
        "# Path to the low-resolution input image\n",
        "input_image_path = \"path_to_your_low_resolution_image.jpg\"\n",
        "\n",
        "# Desired dimensions of the low-resolution image\n",
        "low_res_width, low_res_height = 64, 64\n",
        "\n",
        "# Load and resize the low-resolution input image\n",
        "input_image = Image.open(input_image_path)\n",
        "input_image = input_image.resize((low_res_width, low_res_height))\n",
        "\n",
        "# Convert the input image to a numpy array\n",
        "input_image = tf.keras.preprocessing.image.img_to_array(input_image)\n",
        "\n",
        "# Preprocess the input image by normalizing it to values between 0 and 1\n",
        "input_image = input_image / 255.0\n",
        "\n",
        "# Reshape the input image to match the model's input shape\n",
        "input_image = tf.expand_dims(input_image, axis=0)\n",
        "\n",
        "# Feed the preprocessed low-resolution image into the trained model\n",
        "predicted_image = model.predict(input_image)\n",
        "\n",
        "# Rescale the predicted image back to the original high-resolution dimensions\n",
        "predicted_image = tf.image.resize(predicted_image, (original_high_res_width, original_high_res_height))\n",
        "\n",
        "# Convert the predicted image to a numpy array\n",
        "predicted_image = tf.squeeze(predicted_image, axis=0).numpy()\n",
        "\n",
        "# Post-process the predicted image if necessary\n",
        "# ...\n",
        "\n",
        "# Display or save the predicted high-resolution image\n",
        "predicted_image = Image.fromarray(predicted_image.astype(\"uint8\"))\n",
        "predicted_image.show()\n",
        "predicted_image.save(\"path_to_save_predicted_image.jpg\")\n"
      ],
      "metadata": {
        "id": "dm1b0wIhkV7x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}